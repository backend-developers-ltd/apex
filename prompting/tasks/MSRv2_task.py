import random
from typing import ClassVar, Literal

from loguru import logger

from prompting.datasets.random_website import DDGDatasetEntry
from prompting.rewards.MSRv2_reward import MSRv2RewardModel
from prompting.rewards.reward import BaseRewardConfig, BaseRewardModel
from prompting.tasks.multi_step_reasoning import MultiStepReasoningTask
from shared.base import Context


class MSRv2RewardConfig(BaseRewardConfig):
    reward_definitions: ClassVar[list[BaseRewardModel]] = [
        MSRv2RewardModel(weight=1),
    ]


class MSRv2Task(MultiStepReasoningTask):
    """QuestionAnsweringTasks must be initialised with an LLM pipeline to generate query and reference plus
    context from a dataset to base the query on"""

    name: ClassVar[str] = "multi_step_reasoning_v2"
    augmentation_system_prompt: ClassVar[str] = ""
    generative_miner_answer: str | None = None
    reference: str | None = None
    validator_generated_reference: str | None = None
    miner_generated_reference_capture: str | None = None
    REAL_REFERENCE_PROBABILITY: float = 0.1
    generator_uid: int | None = None

    @property
    def stage(self) -> Literal["generative", "discriminative"]:
        if self.generative_miner_answer or self.reference:
            return "discriminative"
        return "generative"

    @property
    def ground_truth(self) -> int | None:
        """Returns 1 if the reference was generated by the validator, 0 if it was generated by the miner"""
        if self.reference:
            return 1
        elif self.generative_miner_answer:
            return 0
        logger.error("No ground truth for MSRv2Task available yet")
        return None

    def make_query(self, dataset_entry: DDGDatasetEntry):
        if self.stage == "generative":
            # Question to send to miner
            self.query = super().make_query(dataset_entry)
            # Wrapped Query
            self.messages = [{"role": "user", "content": self.query}]
            return self.query
        else:
            return self.reference or self.generative_miner_answer

    async def make_reference(self, dataset_entry: Context):
        if self.stage == "generative":
            # Always generate and store the validator's version of the reference.
            validator_ref_attempt = await super().make_reference(dataset_entry)
            self.validator_generated_reference = (
                validator_ref_attempt if isinstance(validator_ref_attempt, str) else None
            )

            # Decide if the validator's generated reference will be the "official" reference for discrimination.
            if random.random() < self.REAL_REFERENCE_PROBABILITY:
                self.reference = self.validator_generated_reference  # Validator's answer is CHOSEN
                # self.generative_miner_answer remains None in this case, it's not the active reference from task's perspective yet
                return self.reference
            else:
                # Validator's answer is NOT chosen. self.reference remains None.
                # We will use the miner's answer (once received) as the reference.
                # This will be populated into self.generative_miner_answer in the reward model.
                return None  # Indicates we are waiting for the miner's answer to be the reference
        else:
            # return 1 if validator's reference was chosen, 0 if miner's reference was chosen
            return 1 if self.reference else 0

    @property
    def request_body(self) -> dict:
        body = super().request_body
        # By sending this over, we can allow miners to scale their prediction based on the probability of the reference being real
        # so that validators can adjust the probability based on load in later iterations
        body["real_reference_probability"] = self.REAL_REFERENCE_PROBABILITY
        body["stage"] = self.stage
        # if we're in the discriminative stage, we need to send the messages and the miner's answer, otherwise we just send the query
        if self.stage == "discriminative":
            body["messages"] = self.messages + [
                {"role": "assistant", "content": self.reference or self.generative_miner_answer}
            ]
        return body
