{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-15 09:40:47.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mPrompting version: 2.7.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-15 09:40:50.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.utils.config\u001b[0m:\u001b[36mconfig\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mRUNNING WITH ARGS: netuid=None wallet.name=None wallet.hotkey=None subtensor.network=None axon.port=None\u001b[0m\n",
      "\u001b[32m2024-08-15 09:40:50.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.settings\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mConfig: \n",
      "netuid: null\n",
      "wallet:\n",
      "  name: null\n",
      "  hotkey: null\n",
      "subtensor:\n",
      "  network: null\n",
      "axon:\n",
      "  port: null\n",
      "no_prompt: false\n",
      "config: null\n",
      "strict: false\n",
      "no_version_checking: false\n",
      "\u001b[0m\n",
      "\u001b[32m2024-08-15 09:40:50.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.utils.config\u001b[0m:\u001b[36mconfig\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mRUNNING WITH ARGS: netuid=None wallet.name=None wallet.hotkey=None subtensor.network=None axon.port=None\u001b[0m\n",
      "\u001b[32m2024-08-15 09:40:50.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.settings\u001b[0m:\u001b[36mload_env\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mInstantiating bittensor objects with NETUID: 61, WALLET_NAME: validator, HOTKEY: validator_hotkey\u001b[0m\n",
      "\u001b[32m2024-08-15 09:40:54.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.settings\u001b[0m:\u001b[36mload_env\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mBittensor objects instantiated... WALLET: wallet(validator, validator_hotkey, ~/.bittensor/wallets/), SUBTENSOR: subtensor(test, wss://test.finney.opentensor.ai:443/), METAGRAPH: metagraph(netuid:61, n:225, block:2578444, network:test)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode='validator' MOCK=False NO_BACKGROUND_THREAD=True WANDB_ON=True WANDB_ENTITY='felix-quinque-macrocosmos-ai' WANDB_PROJECT_NAME='validator' WANDB_RUN_STEP_LENGTH=100 WANDB_API_KEY='ae29a588c238d0e168d620e0b18a5e29e283935a' WANDB_OFFLINE=False WANDB_NOTES='' SAVE_PATH='./storage' NEURON_EPOCH_LENGTH=1 NEURON_DEVICE='cuda' NEURON_GPUS=1 LOGGING_DONT_SAVE_EVENTS=False NEURON_TIMEOUT=15 NEURON_DISABLE_SET_WEIGHTS=False NEURON_MOVING_AVERAGE_ALPHA=0.1 NEURON_DECAY_ALPHA=0.001 NEURON_AXON_OFF=False NEURON_VPERMIT_TAO_LIMIT=4096 NEURON_QUERY_UNIQUE_COLDKEYS=False NEURON_QUERY_UNIQUE_IPS=False NEURON_FORWARD_MAX_TIME=120 ORGANIC_TIMEOUT=15 ORGANIC_SAMPLE_SIZE=10 ORGANIC_REUSE_RESPONSE_DISABLED=False ORGANIC_REFERENCE_MAX_TOKENS=256 ORGANIC_SYNTH_REWARD_SCALE=1.0 ORGANIC_SET_WEIGHTS_ENABLED=True ORGANIC_DISABLED=False ORGANIC_TRIGGER_FREQUENCY=120 ORGANIC_TRIGGER_FREQUENCY_MIN=5 ORGANIC_TRIGGER='seconds' ORGANIC_SCALING_FACTOR=1 LOG_FULL=False NETUID=61 TEST=True OPENAI_API_KEY='sk-proj-Cq96kZG43OwGM1u3lojpT3BlbkFJqdZJz93Uzre3Z3hdQMfw' WALLET_NAME='validator' HOTKEY='validator_hotkey' AXON_PORT=22118 ORGANIC_WHITELIST_HOTKEY='5F4tQyWrhfGVcNhoqeiNsR6KjD4wMZ2kfhLj4oHYuyHbZAc3' TEST_MINER_IDS=[193] SUBTENSOR_NETWORK='test' WALLET=wallet(validator, validator_hotkey, ~/.bittensor/wallets/) SUBTENSOR=subtensor(test, wss://test.finney.opentensor.ai:443/) METAGRAPH=metagraph(netuid:61, n:225, block:2578444, network:test) NEURON_LLM_MAX_ALLOWED_MEMORY_IN_GB=62 NEURON_MODEL_ID_VALIDATOR='casperhansen/llama-3-70b-instruct-awq'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-15 09:40:55,426\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\u001b[32m2024-08-15 09:40:55.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.llms.utils\u001b[0m:\u001b[36mcalculate_single_gpu_requirements\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mAvailable free memory: 47.34 GB\u001b[0m\n",
      "\u001b[32m2024-08-15 09:40:55.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.llms.utils\u001b[0m:\u001b[36mcalculate_single_gpu_requirements\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mTotal gpu memory 47.62 GB\u001b[0m\n",
      "\u001b[32m2024-08-15 09:40:55.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.llms.utils\u001b[0m:\u001b[36mcalculate_single_gpu_requirements\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m42.0% of the GPU memory will be utilized for loading the model to device \"CUDA\".\u001b[0m\n",
      "\u001b[32m2024-08-15 09:40:55.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.llms.vllm_llm\u001b[0m:\u001b[36mload_vllm_pipeline\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mLoading VLLM pipeline with model_id casperhansen/llama-3-8b-instruct-awq: Max. VRAM: 0.42; GPUs: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialise the LLM we use on the validator\n",
    "from prompting.llms.vllm_llm import vLLMPipeline\n",
    "pipeline = vLLMPipeline(llm_model_id=\"casperhansen/llama-3-8b-instruct-awq\", llm_max_allowed_memory_in_gb=20, device=\"CUDA\", quantization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.15s/it, est. speed input: 1.69 toks/s, output: 61.67 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' * 1+2 is 3.\\n\\n* What\\'s 1+3? * 1+3 is 4.\\n\\n* What\\'s 2+2? * 2+2 is 4.\\n\\n* What\\'s 3+3? * 3+3 is 6.\\n\\n* What\\'s 4+4? * 4+4 is 8.\\n\\nAs you can see, the numbers are getting bigger and bigger, and the answers are getting bigger and bigger too!\\n\\nCan you think of any other questions that would be similar to these ones?\\n\\nChallenge: Think of a different type of question that would have the same pattern as these ones.\\n\\n(Note: You can use symbols, letters, or any other type of input you like!)\\n\\nThink about it for a little bit... and then share your answer with me!  I\\'d love to see what you come up with!\\n\\nHappy thinking! ðŸ¤”\\n\\n(And don\\'t worry if you need a hint or two â€“ I\\'ll be here to help you out!) ðŸŽ‰\" | By | Date | Time | Date | Time | Date | Time | Date | Time | Date | Time | Date | Time | Date | Time | Date | Time | Date | Time | Date | Time |'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see, \"pipeline\" is an object that simply wraps around the LLM and is callable\n",
    "pipeline(\"What's 1+2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Datasets generate 'Context' objects, which contain a 'row' of data, in this case about wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:201: UserWarning: Field name \"name\" in \"WikiDateDataset\" shadows an attribute in parent \"BaseDataset\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Context(title='Iqbal Bhatkal', topic='Terrorism', subtopic=\"He was involved in the Germany bakery blast, which resulted in the death of seventeen and injury of sixty-four people.[4][1] According to Pune Police, Mohsin Chaudhari, an accused for the German Bakery blast was recruited by Iqbal Shabandari, while Iqbal was living in Mumbai. Iqbal made friends with him during a religious function while he was in Pune. Iqbal kept in touch with him constantly for the next three years. With the help of Mohsin and Iqbal's other associates, they were able to set up an Indian Mujahideen base in Pune.[5]  Iqbal Shabandari had started his career as a fervent proselytizer for the largely apolitical Tablighi Jamaat and later on became an Islamist ideologue who recruited several Pune men into the Indian Mujahideen. While the two Bhatkal brothers were living in a rented apartment in Khondwa, Pune they presided over terrorist networks that later carried out multiple bombings across the country.[6]\\n\", content=\"He was involved in the Germany bakery blast, which resulted in the death of seventeen and injury of sixty-four people.[4][1] According to Pune Police, Mohsin Chaudhari, an accused for the German Bakery blast was recruited by Iqbal Shabandari, while Iqbal was living in Mumbai. Iqbal made friends with him during a religious function while he was in Pune. Iqbal kept in touch with him constantly for the next three years. With the help of Mohsin and Iqbal's other associates, they were able to set up an Indian Mujahideen base in Pune.[5]  Iqbal Shabandari had started his career as a fervent proselytizer for the largely apolitical Tablighi Jamaat and later on became an Islamist ideologue who recruited several Pune men into the Indian Mujahideen. While the two Bhatkal brothers were living in a rented apartment in Khondwa, Pune they presided over terrorist networks that later carried out multiple bombings across the country.[6]\\n\", internal_links=['Early life', 'Terrorism'], external_links=['Indian Mujahideen', 'Riyaz Bhatkal', 'Mahmud of Ghazni', 'Muhammad of Ghor', 'Central Bureau of Investigation', 'The Times of India', '2007 Uttar Pradesh bombings', '2010 Pune bombing', 'Batla House encounter case', 'Bhatkal'], source='Wikipedia', tags=['1970 births', 'Anti-Hindu sentiment', 'Fugitives wanted by India', 'Fugitives wanted on terrorism charges', 'Indian Islamists', 'Indian Mujahideen members', 'Indian expatriates in Pakistan', 'Leaders of Islamic terror groups', 'Living people', 'People charged with terrorism', 'People from Uttara Kannada', 'Short description matches Wikidata', 'Tablighi Jamaat people', 'Use Indian English from January 2020', 'Use dmy dates from January 2020', 'Webarchive template wayback links'], extra={'url': 'https://en.wikipedia.org/wiki/Iqbal_Bhatkal', 'page_length': 565, 'section_length': 151}, stats=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompting.datasets.wiki import WikiDataset\n",
    "dataset = WikiDataset()\n",
    "context = dataset.random()\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Tasks are objects that can be used to generate the query & reference for a miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise with past data\n",
    "\n",
    "We can either initialise the task with past data (this doesn't require an LLM to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-15 09:42:17.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mPrompting version: 2.7.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-15 09:42:20.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.utils.config\u001b[0m:\u001b[36mconfig\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mRUNNING WITH ARGS: netuid=None wallet.name=None wallet.hotkey=None subtensor.network=None axon.port=None\u001b[0m\n",
      "\u001b[32m2024-08-15 09:42:20.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.settings\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mConfig: \n",
      "netuid: null\n",
      "wallet:\n",
      "  name: null\n",
      "  hotkey: null\n",
      "subtensor:\n",
      "  network: null\n",
      "axon:\n",
      "  port: null\n",
      "no_prompt: false\n",
      "config: null\n",
      "strict: false\n",
      "no_version_checking: false\n",
      "\u001b[0m\n",
      "\u001b[32m2024-08-15 09:42:21.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.utils.config\u001b[0m:\u001b[36mconfig\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mRUNNING WITH ARGS: netuid=None wallet.name=None wallet.hotkey=None subtensor.network=None axon.port=None\u001b[0m\n",
      "\u001b[32m2024-08-15 09:42:21.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.settings\u001b[0m:\u001b[36mload_env\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mInstantiating bittensor objects with NETUID: 61, WALLET_NAME: validator, HOTKEY: validator_hotkey\u001b[0m\n",
      "\u001b[32m2024-08-15 09:42:25.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprompting.settings\u001b[0m:\u001b[36mload_env\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mBittensor objects instantiated... WALLET: wallet(validator, validator_hotkey, ~/.bittensor/wallets/), SUBTENSOR: subtensor(test, wss://test.finney.opentensor.ai:443/), METAGRAPH: metagraph(netuid:61, n:225, block:2578452, network:test)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode='validator' MOCK=False NO_BACKGROUND_THREAD=True WANDB_ON=True WANDB_ENTITY='felix-quinque-macrocosmos-ai' WANDB_PROJECT_NAME='validator' WANDB_RUN_STEP_LENGTH=100 WANDB_API_KEY='ae29a588c238d0e168d620e0b18a5e29e283935a' WANDB_OFFLINE=False WANDB_NOTES='' SAVE_PATH='./storage' NEURON_EPOCH_LENGTH=1 NEURON_DEVICE='cuda' NEURON_GPUS=1 LOGGING_DONT_SAVE_EVENTS=False NEURON_TIMEOUT=15 NEURON_DISABLE_SET_WEIGHTS=False NEURON_MOVING_AVERAGE_ALPHA=0.1 NEURON_DECAY_ALPHA=0.001 NEURON_AXON_OFF=False NEURON_VPERMIT_TAO_LIMIT=4096 NEURON_QUERY_UNIQUE_COLDKEYS=False NEURON_QUERY_UNIQUE_IPS=False NEURON_FORWARD_MAX_TIME=120 ORGANIC_TIMEOUT=15 ORGANIC_SAMPLE_SIZE=10 ORGANIC_REUSE_RESPONSE_DISABLED=False ORGANIC_REFERENCE_MAX_TOKENS=256 ORGANIC_SYNTH_REWARD_SCALE=1.0 ORGANIC_SET_WEIGHTS_ENABLED=True ORGANIC_DISABLED=False ORGANIC_TRIGGER_FREQUENCY=120 ORGANIC_TRIGGER_FREQUENCY_MIN=5 ORGANIC_TRIGGER='seconds' ORGANIC_SCALING_FACTOR=1 LOG_FULL=False NETUID=61 TEST=True OPENAI_API_KEY='sk-proj-Cq96kZG43OwGM1u3lojpT3BlbkFJqdZJz93Uzre3Z3hdQMfw' WALLET_NAME='validator' HOTKEY='validator_hotkey' AXON_PORT=22118 ORGANIC_WHITELIST_HOTKEY='5F4tQyWrhfGVcNhoqeiNsR6KjD4wMZ2kfhLj4oHYuyHbZAc3' TEST_MINER_IDS=[193] SUBTENSOR_NETWORK='test' WALLET=wallet(validator, validator_hotkey, ~/.bittensor/wallets/) SUBTENSOR=subtensor(test, wss://test.finney.opentensor.ai:443/) METAGRAPH=metagraph(netuid:61, n:225, block:2578452, network:test) NEURON_LLM_MAX_ALLOWED_MEMORY_IN_GB=62 NEURON_MODEL_ID_VALIDATOR='casperhansen/llama-3-70b-instruct-awq'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-15 09:42:25,992\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_type\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from prompting.tasks.summarization import SummarizationTask, SummarizationRewardConfig\n",
    "SummarizationTask.generate_query_reference(llm_pipeline=pipeline, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miner Responses\n",
    "\n",
    "Now let's say we have a few miners giving us responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:201: UserWarning: Field name \"required_hash_fields\" in \"StreamPromptingSynapse\" shadows an attribute in parent \"StreamingSynapse\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from prompting.base.dendrite import DendriteResponseEvent, SynapseStreamResult, StreamPromptingSynapse\n",
    "\n",
    "miner_response_1 = SynapseStreamResult(synapse=StreamPromptingSynapse(completion=\"4\", roles=[\"user\"], messages=[\"What's 1+2?\"]))\n",
    "miner_response_2 = SynapseStreamResult(synapse=StreamPromptingSynapse(completion=\"3\", roles=[\"assistant\"], messages=[\"What's 1+2?\"]))\n",
    "\n",
    "\n",
    "# the synapses from all miners get collected into the DenriteResponseEvent\n",
    "dendrite_response = DendriteResponseEvent(stream_results=[miner_response_1, miner_response_2], uids=[1, 2], timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "\n",
    "We can now pass the query, reference and miner responses to our scoring function, which is then responsible for giving each miner a score which is later used to set weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-05 11:10:37,316\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/prompting-fb5sw-i7-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_type\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.34321602, 0.78916947])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompting.tasks.summarization import SummarizationRewardConfig\n",
    "\n",
    "reward_events, penality_events, rewards = SummarizationRewardConfig.apply(challenge=\"What's 1+2?\", reference=\"1+2 is equal to 3\", response_event=dendrite_response)\n",
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other tests/examples on different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompting.tasks.qa import QuestionAnsweringTask, QARewardConfig\n",
    "qa = QuestionAnsweringTask(context=context, llm_pipeline=pipeline, reward_config=SummarizationRewardConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.generate_query(pipeline=pipeline)\n",
    "qa.generate_reference(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 139.69 toks/s, output: 343.83 toks/s]\n",
      "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.40it/s, est. speed input: 567.92 toks/s, output: 360.75 toks/s]\n"
     ]
    }
   ],
   "source": [
    "qa_task = QuestionAnsweringTask(llm_pipeline=pipeline, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{{ Answer the question you will receive in detail, utilizing the following context.\n",
      "\n",
      "# Context:\n",
      "\n",
      "History\n",
      "\n",
      "# Question:\n",
      "\n",
      "None\n",
      "\n",
      " }}<|eot_id|><|start_header_id|>presenter<|end_header_id|>\n",
      "\n",
      "{{ Answer the question you will receive in detail, utilizing the following context.\n",
      "\n",
      "# Context:\n",
      "\n",
      "History\n",
      "\n",
      "# Question:\n",
      "\n",
      "None\n",
      "\n",
      " }}<|eot_id|><|start_header_id|>active<|end_header_id|>\n",
      "\n",
      "{{ Answer the question you will receive in detail, utilizing the following context.\n",
      "\n",
      "# Context:\n",
      "\n",
      "History\n",
      "\n",
      "# Question:\n",
      "\n",
      "None\n",
      "\n",
      " }}<|eot_id|><|start_header_id|>active<|end_header_id|>\n",
      "\n",
      "{{ Answer the question you will receive in detail, utilizing the following context.\n",
      "\n",
      "# Context:\n",
      "\n",
      "History\n",
      "\n",
      "# Question:\n",
      "\n",
      "None\n",
      "\n",
      " }}<|eot_id|><|start_header_id|>active<|end_header_id|>\n",
      "\n",
      "{{ Answer the question you\n"
     ]
    }
   ],
   "source": [
    "print(qa_task.reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaskConfig(), TaskConfig()]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskRegistry.tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompting-fb5sw-i7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
